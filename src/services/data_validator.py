#!/usr/bin/env python3
"""
ë°ì´í„° ê²€ì¦ ëª¨ë“ˆ - ë² íŠ¸ë§¨ í¬ë¡¤ëŸ¬ vs KSPO API ë°ì´í„° ë¹„êµ

í•µì‹¬ ê¸°ëŠ¥:
1. ë‘ ì†ŒìŠ¤ ê°„ ë°ì´í„° ë¹„êµ ë° ë¶ˆì¼ì¹˜ ê°ì§€
2. íŒ€ëª… ì •ê·œí™” ë° ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
3. ë¶ˆì¼ì¹˜ ìœ í˜• ë¶„ë¥˜ ë° ìë™ ìˆ˜ì • ì œì•ˆ
4. ê²€ì¦ ë³´ê³ ì„œ ìƒì„±

ì‚¬ìš© ì˜ˆì‹œ:
    validator = DataValidator()
    result = await validator.compare_sources("soccer_wdl")
    report = await validator.generate_report()
    print(report)
"""

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime
from difflib import SequenceMatcher
from enum import Enum
from typing import Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


class MismatchType(Enum):
    """ë¶ˆì¼ì¹˜ ìœ í˜•"""
    TEAM_NAME_MISMATCH = "team_name_mismatch"  # íŒ€ëª… ë¶ˆì¼ì¹˜
    GAME_COUNT_MISMATCH = "game_count_mismatch"  # ê²½ê¸° ìˆ˜ ë¶ˆì¼ì¹˜
    ORDER_MISMATCH = "order_mismatch"  # ê²½ê¸° ìˆœì„œ ë¶ˆì¼ì¹˜
    DATE_TIME_MISMATCH = "date_time_mismatch"  # ë‚ ì§œ/ì‹œê°„ ë¶ˆì¼ì¹˜
    ROUND_MISMATCH = "round_mismatch"  # íšŒì°¨ ë²ˆí˜¸ ë¶ˆì¼ì¹˜
    MISSING_GAME = "missing_game"  # ê²½ê¸° ëˆ„ë½


@dataclass
class Mismatch:
    """ë¶ˆì¼ì¹˜ í•­ëª©"""
    game_number: int
    mismatch_type: MismatchType
    field: str  # "home_team", "away_team", "date", "time", "round"
    crawler_value: str
    api_value: str
    similarity: float  # 0~1 ìœ ì‚¬ë„
    suggested_action: str  # "use_crawler", "use_api", "manual_review"
    description: str = ""  # ì¶”ê°€ ì„¤ëª…

    def __str__(self):
        return (
            f"ê²½ê¸° {self.game_number:02d} - {self.field}: "
            f"í¬ë¡¤ëŸ¬='{self.crawler_value}' vs API='{self.api_value}' "
            f"(ìœ ì‚¬ë„: {self.similarity:.1%}, ê¶Œì¥: {self.suggested_action})"
        )


@dataclass
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼"""
    is_valid: bool  # 100% ì¼ì¹˜ ì—¬ë¶€
    match_rate: float  # ì¼ì¹˜ìœ¨ 0~1
    total_games: int  # ì´ ê²½ê¸° ìˆ˜
    matched_games: int  # ì¼ì¹˜í•˜ëŠ” ê²½ê¸° ìˆ˜
    mismatches: List[Mismatch] = field(default_factory=list)  # ë¶ˆì¼ì¹˜ í•­ëª©ë“¤
    crawler_data: Optional[Tuple] = None  # (RoundInfo, List[Dict])
    api_data: Optional[Tuple] = None  # (RoundInfo, List[Dict])
    validated_at: datetime = field(default_factory=datetime.now)

    def __str__(self):
        status = "âœ… ì¼ì¹˜" if self.is_valid else "âš ï¸ ë¶ˆì¼ì¹˜"
        return (
            f"{status} - ì¼ì¹˜ìœ¨: {self.match_rate:.1%} "
            f"({self.matched_games}/{self.total_games}ê²½ê¸°)"
        )


class DataValidator:
    """ë°ì´í„° ê²€ì¦ê¸°"""

    # íŒ€ëª… ì •ê·œí™” ë§¤í•‘ (ì•½ì–´ ë° ë³€í˜• ì²˜ë¦¬)
    TEAM_NAME_MAPPINGS = {
        # ì¶•êµ¬ íŒ€ëª…
        "ë ˆìŠ¤í„°ì‹œí‹°": ["ë ˆìŠ¤í„°C", "ë ˆìŠ¤í„°", "ë ˆìŠ¤í„° ì‹œí‹°"],
        "ë§¨ì²´ìŠ¤í„°ìœ ë‚˜ì´í‹°ë“œ": ["ë§¨ì²´ìŠ¤U", "ë§¨ìœ ", "ë§¨ì²´ìŠ¤í„°U", "ë§¨ì²´ìŠ¤í„° ìœ ë‚˜ì´í‹°ë“œ"],
        "ë§¨ì²´ìŠ¤í„°ì‹œí‹°": ["ë§¨ì‹œí‹°", "ë§¨ì²´ìŠ¤í„°C", "ë§¨ì²´ìŠ¤í„° ì‹œí‹°"],
        "í† íŠ¸ë„˜í™‹ìŠ¤í¼": ["í† íŠ¸ë„˜", "í† íŠ¸ë„˜í™‹"],
        "ë…¸íŒ…ì—„í¬ë ˆìŠ¤íŠ¸": ["ë…¸íŒ…ì—„F", "ë…¸íŒ…ì—„", "ë…¸íŒ…ì—„ í¬ë ˆìŠ¤íŠ¸"],
        "ì›¨ìŠ¤íŠ¸í–„ìœ ë‚˜ì´í‹°ë“œ": ["ì›¨ìŠ¤íŠ¸í–„U", "ì›¨ìŠ¤íŠ¸í–„", "ì›¨ìŠ¤íŠ¸í–„U"],
        "ë‰´ìºìŠ¬ìœ ë‚˜ì´í‹°ë“œ": ["ë‰´ìºìŠ¬U", "ë‰´ìºìŠ¬", "ë‰´ìºìŠ¬U"],

        # ë†êµ¬ íŒ€ëª…
        "ìš¸ì‚°í˜„ëŒ€ëª¨ë¹„ìŠ¤": ["ìš¸ì‚°ëª¨ë¹„ìŠ¤", "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "ëª¨ë¹„ìŠ¤"],
        "ìˆ˜ì›KTì†Œë‹‰ë¶": ["ìˆ˜ì›KT", "KTì†Œë‹‰ë¶", "KT"],
        "ì„œìš¸ì‚¼ì„±ì¬ë”ìŠ¤": ["ì„œìš¸ì‚¼ì„±", "ì‚¼ì„±ì¬ë”ìŠ¤", "ì‚¼ì„±"],
        "ì°½ì›LGì„¸ì´ì»¤ìŠ¤": ["ì°½ì›LG", "LGì„¸ì´ì»¤ìŠ¤", "LG"],
        "ì•ˆì–‘ì •ê´€ì¥ë ˆë“œë¶€ìŠ¤í„°": ["ì•ˆì–‘ì •ê´€ì¥", "ì •ê´€ì¥", "ì•ˆì–‘"],
        "ê³ ì–‘ì†Œë…¸ìŠ¤ì¹´ì´ê±°ë„ˆìŠ¤": ["ê³ ì–‘ì†Œë…¸", "ì†Œë…¸", "ê³ ì–‘"],
        "ì„œìš¸SKë‚˜ì´ì¸ ": ["ì„œìš¸SK", "SKë‚˜ì´ì¸ ", "SK"],
        "ë¶€ì‚°KCCì´ì§€ìŠ¤": ["ë¶€ì‚°KCC", "KCCì´ì§€ìŠ¤", "KCC"],
        "ëŒ€êµ¬í•œêµ­ê°€ìŠ¤ê³µì‚¬": ["ëŒ€êµ¬ê°€ìŠ¤ê³µì‚¬", "í•œêµ­ê°€ìŠ¤ê³µì‚¬", "ê°€ìŠ¤ê³µì‚¬"],
        "ì „ì£¼KCCì´ì§€ìŠ¤": ["ì „ì£¼KCC", "KCC"],

        # NBA íŒ€ëª… (í•„ìš”ì‹œ ì¶”ê°€)
        "ê³¨ë“ ìŠ¤í…Œì´íŠ¸ì›Œë¦¬ì–´ìŠ¤": ["ê³¨ë“ ìŠ¤í…Œì´íŠ¸", "ì›Œë¦¬ì–´ìŠ¤", "GSW"],
        "ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤ë ˆì´ì»¤ìŠ¤": ["LAë ˆì´ì»¤ìŠ¤", "ë ˆì´ì»¤ìŠ¤", "LAL"],
    }

    def __init__(self):
        # ì—­ë§¤í•‘ ìƒì„± (ì•½ì–´ -> ì •ì‹ëª…)
        self._reverse_mappings: Dict[str, str] = {}
        for full_name, aliases in self.TEAM_NAME_MAPPINGS.items():
            for alias in aliases:
                self._reverse_mappings[alias] = full_name
            self._reverse_mappings[full_name] = full_name

    # ========== ë©”ì¸ ê²€ì¦ ë¡œì§ ==========

    async def compare_sources(
        self,
        game_type: str = "soccer_wdl",
        use_cache: bool = False
    ) -> ValidationResult:
        """
        í¬ë¡¤ëŸ¬ ë°ì´í„°ì™€ API ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ ë¶ˆì¼ì¹˜ í•­ëª© ë°˜í™˜

        Args:
            game_type: "soccer_wdl" | "basketball_w5l"
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (Falseë©´ ê°•ì œ ìƒˆë¡œê³ ì¹¨)

        Returns:
            ValidationResult: ê²€ì¦ ê²°ê³¼
        """
        from src.services.round_manager import RoundManager

        manager = RoundManager()

        # 1. ë‘ ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        logger.info(f"ë°ì´í„° ê²€ì¦ ì‹œì‘: {game_type}")

        try:
            # í¬ë¡¤ëŸ¬ ë°ì´í„°
            if game_type == "soccer_wdl":
                crawler_info, crawler_games = await manager.get_soccer_wdl_round(
                    force_refresh=not use_cache,
                    source="crawler"
                )
            else:  # basketball_w5l
                crawler_info, crawler_games = await manager.get_basketball_w5l_round(
                    force_refresh=not use_cache,
                    source="crawler"
                )
            logger.info(f"âœ… í¬ë¡¤ëŸ¬: {crawler_info.round_number}íšŒì°¨ {len(crawler_games)}ê²½ê¸°")
        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ëŸ¬ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            crawler_info = None
            crawler_games = []

        try:
            # API ë°ì´í„°
            if game_type == "soccer_wdl":
                api_info, api_games = await manager.get_soccer_wdl_round(
                    force_refresh=not use_cache,
                    source="api"
                )
            else:  # basketball_w5l
                api_info, api_games = await manager.get_basketball_w5l_round(
                    force_refresh=not use_cache,
                    source="api"
                )
            logger.info(f"âœ… API: {api_info.round_number}íšŒì°¨ {len(api_games)}ê²½ê¸°")
        except Exception as e:
            logger.error(f"âŒ API ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            api_info = None
            api_games = []

        # 2. ë°ì´í„° ë¹„êµ
        mismatches = []

        # ê²½ê¸° ìˆ˜ ê²€ì¦
        crawler_count = len(crawler_games)
        api_count = len(api_games)

        if crawler_count != api_count:
            mismatches.append(Mismatch(
                game_number=0,
                mismatch_type=MismatchType.GAME_COUNT_MISMATCH,
                field="game_count",
                crawler_value=str(crawler_count),
                api_value=str(api_count),
                similarity=0.0,
                suggested_action="use_crawler" if crawler_count == 14 else "manual_review",
                description=f"ê²½ê¸° ìˆ˜ ë¶ˆì¼ì¹˜: í¬ë¡¤ëŸ¬ {crawler_count}ê²½ê¸° vs API {api_count}ê²½ê¸°"
            ))

        # íšŒì°¨ ë²ˆí˜¸ ê²€ì¦
        if crawler_info and api_info and crawler_info.round_number != api_info.round_number:
            mismatches.append(Mismatch(
                game_number=0,
                mismatch_type=MismatchType.ROUND_MISMATCH,
                field="round_number",
                crawler_value=str(crawler_info.round_number),
                api_value=str(api_info.round_number),
                similarity=0.0,
                suggested_action="use_crawler",
                description=f"íšŒì°¨ ë²ˆí˜¸ ë¶ˆì¼ì¹˜: í¬ë¡¤ëŸ¬ {crawler_info.round_number}íšŒ vs API {api_info.round_number}íšŒ"
            ))

        # 3. ê²½ê¸°ë³„ ë¹„êµ (ì‘ì€ ìª½ ê¸°ì¤€)
        min_count = min(crawler_count, api_count)
        matched_count = 0

        for i in range(min_count):
            crawler_game = crawler_games[i]
            api_game = api_games[i]

            game_mismatches = self._compare_game(i + 1, crawler_game, api_game)

            if not game_mismatches:
                matched_count += 1
            else:
                mismatches.extend(game_mismatches)

        # 4. ëˆ„ë½ëœ ê²½ê¸° ì²˜ë¦¬
        if crawler_count > api_count:
            for i in range(api_count, crawler_count):
                mismatches.append(Mismatch(
                    game_number=i + 1,
                    mismatch_type=MismatchType.MISSING_GAME,
                    field="game",
                    crawler_value=f"{crawler_games[i].get('hteam_han_nm', '')} vs {crawler_games[i].get('ateam_han_nm', '')}",
                    api_value="(ì—†ìŒ)",
                    similarity=0.0,
                    suggested_action="use_crawler",
                    description="APIì— ê²½ê¸° ëˆ„ë½"
                ))
        elif api_count > crawler_count:
            for i in range(crawler_count, api_count):
                mismatches.append(Mismatch(
                    game_number=i + 1,
                    mismatch_type=MismatchType.MISSING_GAME,
                    field="game",
                    crawler_value="(ì—†ìŒ)",
                    api_value=f"{api_games[i].get('hteam_han_nm', '')} vs {api_games[i].get('ateam_han_nm', '')}",
                    similarity=0.0,
                    suggested_action="manual_review",
                    description="í¬ë¡¤ëŸ¬ì— ê²½ê¸° ëˆ„ë½"
                ))

        # 5. ê²°ê³¼ ìƒì„±
        total_games = max(crawler_count, api_count)
        match_rate = matched_count / total_games if total_games > 0 else 0.0
        is_valid = len(mismatches) == 0

        result = ValidationResult(
            is_valid=is_valid,
            match_rate=match_rate,
            total_games=total_games,
            matched_games=matched_count,
            mismatches=mismatches,
            crawler_data=(crawler_info, crawler_games) if crawler_info else None,
            api_data=(api_info, api_games) if api_info else None,
            validated_at=datetime.now()
        )

        logger.info(f"ê²€ì¦ ì™„ë£Œ: {result}")
        return result

    def _compare_game(self, game_number: int, crawler_game: Dict, api_game: Dict) -> List[Mismatch]:
        """ê°œë³„ ê²½ê¸° ë¹„êµ"""
        mismatches = []

        # í™ˆíŒ€ ë¹„êµ
        crawler_home = crawler_game.get("hteam_han_nm", "")
        api_home = api_game.get("hteam_han_nm", "")

        home_similarity = self._calculate_team_similarity(crawler_home, api_home)
        if home_similarity < 0.9:  # 90% ë¯¸ë§Œì´ë©´ ë¶ˆì¼ì¹˜
            mismatches.append(Mismatch(
                game_number=game_number,
                mismatch_type=MismatchType.TEAM_NAME_MISMATCH,
                field="home_team",
                crawler_value=crawler_home,
                api_value=api_home,
                similarity=home_similarity,
                suggested_action=self._suggest_action(home_similarity),
                description=f"í™ˆíŒ€ëª… ë¶ˆì¼ì¹˜"
            ))

        # ì›ì •íŒ€ ë¹„êµ
        crawler_away = crawler_game.get("ateam_han_nm", "")
        api_away = api_game.get("ateam_han_nm", "")

        away_similarity = self._calculate_team_similarity(crawler_away, api_away)
        if away_similarity < 0.9:
            mismatches.append(Mismatch(
                game_number=game_number,
                mismatch_type=MismatchType.TEAM_NAME_MISMATCH,
                field="away_team",
                crawler_value=crawler_away,
                api_value=api_away,
                similarity=away_similarity,
                suggested_action=self._suggest_action(away_similarity),
                description=f"ì›ì •íŒ€ëª… ë¶ˆì¼ì¹˜"
            ))

        # ë‚ ì§œ ë¹„êµ
        crawler_date = crawler_game.get("match_ymd", "")
        api_date = api_game.get("match_ymd", "")

        if crawler_date != api_date:
            mismatches.append(Mismatch(
                game_number=game_number,
                mismatch_type=MismatchType.DATE_TIME_MISMATCH,
                field="date",
                crawler_value=crawler_date,
                api_value=api_date,
                similarity=0.0,
                suggested_action="use_crawler",
                description=f"ê²½ê¸° ë‚ ì§œ ë¶ˆì¼ì¹˜"
            ))

        # ì‹œê°„ ë¹„êµ (5ë¶„ ì˜¤ì°¨ í—ˆìš©)
        crawler_time = str(crawler_game.get("match_tm", "0000")).zfill(4)
        api_time = str(api_game.get("match_tm", "0000")).zfill(4)

        time_diff = self._calculate_time_diff(crawler_time, api_time)
        if time_diff > 5:  # 5ë¶„ ì´ˆê³¼ ì°¨ì´
            mismatches.append(Mismatch(
                game_number=game_number,
                mismatch_type=MismatchType.DATE_TIME_MISMATCH,
                field="time",
                crawler_value=crawler_time,
                api_value=api_time,
                similarity=0.0,
                suggested_action="use_crawler",
                description=f"ê²½ê¸° ì‹œê°„ ë¶ˆì¼ì¹˜ ({time_diff}ë¶„ ì°¨ì´)"
            ))

        return mismatches

    # ========== íŒ€ëª… ì •ê·œí™” ë° ìœ ì‚¬ë„ ê³„ì‚° ==========

    def _normalize_team_name(self, team_name: str) -> str:
        """íŒ€ëª… ì •ê·œí™”"""
        # ê³µë°± ì œê±°
        team_name = team_name.strip().replace(" ", "")

        # ë§¤í•‘ í…Œì´ë¸”ì—ì„œ ì •ì‹ ëª…ì¹­ ì°¾ê¸°
        if team_name in self._reverse_mappings:
            return self._reverse_mappings[team_name]

        # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
        for full_name, aliases in self.TEAM_NAME_MAPPINGS.items():
            if team_name in aliases or team_name == full_name:
                return full_name
            # í¬í•¨ ê´€ê³„ í™•ì¸
            for alias in aliases:
                if team_name in alias or alias in team_name:
                    return full_name

        return team_name

    def _calculate_team_similarity(self, team1: str, team2: str) -> float:
        """
        íŒ€ëª… ìœ ì‚¬ë„ ê³„ì‚°

        Returns:
            0~1 ìœ ì‚¬ë„ (1.0 = ì™„ì „ ì¼ì¹˜)
        """
        if not team1 or not team2:
            return 0.0

        # ì •ê·œí™”
        norm1 = self._normalize_team_name(team1)
        norm2 = self._normalize_team_name(team2)

        # ì •ê·œí™” í›„ ì¼ì¹˜í•˜ë©´ 1.0
        if norm1 == norm2:
            return 1.0

        # ì›ë³¸ì´ ì¼ì¹˜í•˜ë©´ 1.0
        if team1 == team2:
            return 1.0

        # SequenceMatcherë¡œ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = SequenceMatcher(None, norm1, norm2).ratio()

        # ì¶”ê°€: í•œìª½ì´ ë‹¤ë¥¸ ìª½ì„ í¬í•¨í•˜ë©´ ë³´ë„ˆìŠ¤
        if norm1 in norm2 or norm2 in norm1:
            similarity = max(similarity, 0.8)

        return similarity

    def _calculate_time_diff(self, time1: str, time2: str) -> int:
        """
        ì‹œê°„ ì°¨ì´ ê³„ì‚° (ë¶„ ë‹¨ìœ„)

        Args:
            time1, time2: HHMM í˜•ì‹

        Returns:
            ë¶„ ë‹¨ìœ„ ì°¨ì´
        """
        try:
            h1, m1 = int(time1[:2]), int(time1[2:4])
            h2, m2 = int(time2[:2]), int(time2[2:4])

            min1 = h1 * 60 + m1
            min2 = h2 * 60 + m2

            return abs(min1 - min2)
        except (ValueError, IndexError):
            return 0

    def _suggest_action(self, similarity: float) -> str:
        """
        ìœ ì‚¬ë„ì— ë”°ë¥¸ ìˆ˜ì • ì œì•ˆ

        Args:
            similarity: 0~1 ìœ ì‚¬ë„

        Returns:
            "use_crawler" | "use_api" | "manual_review"
        """
        if similarity >= 0.7:
            return "use_crawler"  # í¬ë¡¤ëŸ¬ê°€ ë” ì •í™•í•¨
        elif similarity >= 0.3:
            return "manual_review"  # ìˆ˜ë™ ê²€í†  í•„ìš”
        else:
            return "manual_review"  # ì™„ì „íˆ ë‹¤ë¦„

    # ========== ë³´ê³ ì„œ ìƒì„± ==========

    async def generate_report(
        self,
        game_type: str = "soccer_wdl",
        use_cache: bool = False
    ) -> str:
        """
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ê²€ì¦ ë³´ê³ ì„œ ìƒì„±

        Args:
            game_type: "soccer_wdl" | "basketball_w5l"
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë³´ê³ ì„œ
        """
        result = await self.compare_sources(game_type, use_cache)

        # í—¤ë”
        game_type_name = "ì¶•êµ¬ ìŠ¹ë¬´íŒ¨" if game_type == "soccer_wdl" else "ë†êµ¬ ìŠ¹5íŒ¨"
        status_emoji = "âœ…" if result.is_valid else "âš ï¸"

        report = [
            "# ë°ì´í„° ê²€ì¦ ë³´ê³ ì„œ",
            f"## {game_type_name}",
            "",
            f"**ê²€ì¦ ì‹œê°**: {result.validated_at.strftime('%Y-%m-%d %H:%M:%S')}",
            f"**ê²€ì¦ ê²°ê³¼**: {status_emoji} {'ì¼ì¹˜' if result.is_valid else 'ë¶ˆì¼ì¹˜'}",
            f"**ì¼ì¹˜ìœ¨**: {result.match_rate:.1%} ({result.matched_games}/{result.total_games}ê²½ê¸°)",
            "",
            "---",
            "",
        ]

        # íšŒì°¨ ì •ë³´
        if result.crawler_data and result.api_data:
            crawler_info, crawler_games = result.crawler_data
            api_info, api_games = result.api_data

            report.extend([
                "## ë°ì´í„° ì†ŒìŠ¤ ì •ë³´",
                "",
                "| í•­ëª© | ë² íŠ¸ë§¨ í¬ë¡¤ëŸ¬ | KSPO API |",
                "|------|--------------|----------|",
                f"| íšŒì°¨ ë²ˆí˜¸ | {crawler_info.round_number}íšŒ | {api_info.round_number}íšŒ |",
                f"| ê²½ê¸° ìˆ˜ | {len(crawler_games)}ê²½ê¸° | {len(api_games)}ê²½ê¸° |",
                f"| ê²½ê¸° ë‚ ì§œ | {crawler_info.match_date} | {api_info.match_date} |",
                f"| ìƒíƒœ | {crawler_info.status} | {api_info.status} |",
                "",
                "---",
                "",
            ])

        # ë¶ˆì¼ì¹˜ í•­ëª©
        if result.mismatches:
            report.extend([
                f"## ë¶ˆì¼ì¹˜ í•­ëª© ({len(result.mismatches)}ê±´)",
                "",
            ])

            # ìœ í˜•ë³„ ê·¸ë£¹í™”
            by_type: Dict[MismatchType, List[Mismatch]] = {}
            for m in result.mismatches:
                by_type.setdefault(m.mismatch_type, []).append(m)

            for mismatch_type, items in by_type.items():
                type_name_map = {
                    MismatchType.TEAM_NAME_MISMATCH: "íŒ€ëª… ë¶ˆì¼ì¹˜",
                    MismatchType.GAME_COUNT_MISMATCH: "ê²½ê¸° ìˆ˜ ë¶ˆì¼ì¹˜",
                    MismatchType.ORDER_MISMATCH: "ê²½ê¸° ìˆœì„œ ë¶ˆì¼ì¹˜",
                    MismatchType.DATE_TIME_MISMATCH: "ë‚ ì§œ/ì‹œê°„ ë¶ˆì¼ì¹˜",
                    MismatchType.ROUND_MISMATCH: "íšŒì°¨ ë²ˆí˜¸ ë¶ˆì¼ì¹˜",
                    MismatchType.MISSING_GAME: "ê²½ê¸° ëˆ„ë½",
                }

                report.extend([
                    f"### {type_name_map.get(mismatch_type, str(mismatch_type))} ({len(items)}ê±´)",
                    "",
                    "| ê²½ê¸° | í•„ë“œ | í¬ë¡¤ëŸ¬ | API | ìœ ì‚¬ë„ | ê¶Œì¥ ì¡°ì¹˜ |",
                    "|------|------|--------|-----|--------|-----------|",
                ])

                for m in items:
                    game_num = f"{m.game_number:02d}" if m.game_number > 0 else "-"
                    similarity_str = f"{m.similarity:.1%}" if m.similarity > 0 else "-"
                    action_map = {
                        "use_crawler": "í¬ë¡¤ëŸ¬ ì‚¬ìš©",
                        "use_api": "API ì‚¬ìš©",
                        "manual_review": "ìˆ˜ë™ ê²€í† "
                    }
                    action = action_map.get(m.suggested_action, m.suggested_action)

                    report.append(
                        f"| {game_num} | {m.field} | {m.crawler_value} | {m.api_value} | "
                        f"{similarity_str} | {action} |"
                    )

                report.append("")
        else:
            report.extend([
                "## ê²€ì¦ ê²°ê³¼",
                "",
                "ëª¨ë“  ë°ì´í„°ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤.",
                "",
            ])

        # ê¶Œì¥ ì‚¬í•­
        report.extend([
            "---",
            "",
            "## ê¶Œì¥ ì‚¬í•­",
            "",
        ])

        if result.is_valid:
            report.extend([
                "- ë‘ ì†ŒìŠ¤ì˜ ë°ì´í„°ê°€ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤.",
                "- ì–´ë–¤ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.",
                "",
            ])
        else:
            # í¬ë¡¤ëŸ¬ ê¶Œì¥ ê°œìˆ˜
            crawler_recommended = sum(1 for m in result.mismatches if m.suggested_action == "use_crawler")
            api_recommended = sum(1 for m in result.mismatches if m.suggested_action == "use_api")
            manual_review = sum(1 for m in result.mismatches if m.suggested_action == "manual_review")

            report.extend([
                f"- **í¬ë¡¤ëŸ¬ ì‚¬ìš© ê¶Œì¥**: {crawler_recommended}ê±´",
                f"- **API ì‚¬ìš© ê¶Œì¥**: {api_recommended}ê±´",
                f"- **ìˆ˜ë™ ê²€í†  í•„ìš”**: {manual_review}ê±´",
                "",
            ])

            if crawler_recommended > api_recommended:
                report.extend([
                    "**ê²°ë¡ **: ë² íŠ¸ë§¨ í¬ë¡¤ëŸ¬ ë°ì´í„° ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
                    "",
                    "ì´ìœ :",
                    "- í¬ë¡¤ëŸ¬ëŠ” ë² íŠ¸ë§¨ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ ìˆ˜ì§‘í•˜ë¯€ë¡œ ë” ì •í™•í•©ë‹ˆë‹¤.",
                    "- KSPO APIëŠ” turn_no ëˆ„ë½, ê²½ê¸° ëˆ„ë½ ë“±ì˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.",
                    "",
                ])
            else:
                report.extend([
                    "**ê²°ë¡ **: ìˆ˜ë™ ê²€í†  í›„ ê²°ì •í•˜ì„¸ìš”.",
                    "",
                ])

        # ê²½ê¸° ëª©ë¡ ìƒì„¸ ë¹„êµ (ì²« 5ê²½ê¸°ë§Œ)
        if result.crawler_data and result.api_data:
            crawler_info, crawler_games = result.crawler_data
            api_info, api_games = result.api_data

            report.extend([
                "---",
                "",
                "## ê²½ê¸° ëª©ë¡ ìƒì„¸ ë¹„êµ (ì²˜ìŒ 5ê²½ê¸°)",
                "",
            ])

            for i in range(min(5, len(crawler_games), len(api_games))):
                c_game = crawler_games[i]
                a_game = api_games[i]

                c_home = c_game.get("hteam_han_nm", "")
                c_away = c_game.get("ateam_han_nm", "")
                c_time = str(c_game.get("match_tm", "0000")).zfill(4)

                a_home = a_game.get("hteam_han_nm", "")
                a_away = a_game.get("ateam_han_nm", "")
                a_time = str(a_game.get("match_tm", "0000")).zfill(4)

                match_emoji = "âœ…" if (c_home == a_home and c_away == a_away) else "âš ï¸"

                report.extend([
                    f"### {i+1:02d}ë²ˆ ê²½ê¸° {match_emoji}",
                    "",
                    f"**í¬ë¡¤ëŸ¬**: {c_home} vs {c_away} ({c_time[:2]}:{c_time[2:]})",
                    f"**API**: {a_home} vs {a_away} ({a_time[:2]}:{a_time[2:]})",
                    "",
                ])

        return "\n".join(report)

    async def get_validation_summary(self, game_type: str = "soccer_wdl") -> Dict:
        """
        ê²€ì¦ ê²°ê³¼ ìš”ì•½ (JSON í˜•ì‹)

        Returns:
            {
                "is_valid": bool,
                "match_rate": float,
                "total_games": int,
                "mismatches_count": int,
                "recommended_source": "crawler" | "api" | "manual",
            }
        """
        result = await self.compare_sources(game_type)

        # ê¶Œì¥ ì†ŒìŠ¤ ê²°ì •
        crawler_recommended = sum(1 for m in result.mismatches if m.suggested_action == "use_crawler")
        api_recommended = sum(1 for m in result.mismatches if m.suggested_action == "use_api")

        if result.is_valid:
            recommended = "both"
        elif crawler_recommended > api_recommended:
            recommended = "crawler"
        elif api_recommended > crawler_recommended:
            recommended = "api"
        else:
            recommended = "manual"

        return {
            "is_valid": result.is_valid,
            "match_rate": result.match_rate,
            "total_games": result.total_games,
            "matched_games": result.matched_games,
            "mismatches_count": len(result.mismatches),
            "recommended_source": recommended,
            "validated_at": result.validated_at.isoformat(),
        }


# ========== í…ŒìŠ¤íŠ¸ ==========

async def test_validator():
    """ê²€ì¦ê¸° í…ŒìŠ¤íŠ¸"""
    import sys

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
    )

    validator = DataValidator()

    # ì¶•êµ¬ ìŠ¹ë¬´íŒ¨ ê²€ì¦
    print("=" * 80)
    print("âš½ ì¶•êµ¬ ìŠ¹ë¬´íŒ¨ ë°ì´í„° ê²€ì¦")
    print("=" * 80)
    print()

    try:
        report = await validator.generate_report("soccer_wdl", use_cache=False)
        print(report)
        print()

        # ìš”ì•½ ì •ë³´
        summary = await validator.get_validation_summary("soccer_wdl")
        print("=" * 80)
        print("ê²€ì¦ ìš”ì•½ (JSON)")
        print("=" * 80)
        import json
        print(json.dumps(summary, indent=2, ensure_ascii=False))

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

    print()
    print("=" * 80)
    print("ğŸ€ ë†êµ¬ ìŠ¹5íŒ¨ ë°ì´í„° ê²€ì¦")
    print("=" * 80)
    print()

    try:
        report = await validator.generate_report("basketball_w5l", use_cache=False)
        print(report)
        print()

        summary = await validator.get_validation_summary("basketball_w5l")
        print("=" * 80)
        print("ê²€ì¦ ìš”ì•½ (JSON)")
        print("=" * 80)
        import json
        print(json.dumps(summary, indent=2, ensure_ascii=False))

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test_validator())

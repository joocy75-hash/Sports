"""
í”„ë¡œí†  ë¶„ì„ ë¹„ìš© ìµœì í™” ì„œë¹„ìŠ¤

í”„ë¡œí†  ì¶”ì²¨ ì¼ì •ì— ë§ì¶° AI ë¶„ì„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ì—¬ ë¹„ìš© ì ˆê°
"""

from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional
import logging
from enum import Enum

logger = logging.getLogger(__name__)


class AnalysisMode(Enum):
    """ë¶„ì„ ëª¨ë“œ"""
    FULL = "full"  # ìµœìƒìœ„ ëª¨ë¸ë¡œ ì „ì²´ ë¶„ì„
    QUICK = "quick"  # ê°„ë‹¨í•œ ì‚¬ì „ ë¶„ì„
    CACHED = "cached"  # ìºì‹œëœ ê²°ê³¼ ì‚¬ìš©


class ProtoSchedule:
    """í”„ë¡œí†  ì¶”ì²¨ ì¼ì • ê´€ë¦¬"""

    # í”„ë¡œí†  ì¶”ì²¨ì¼ (ìš”ì¼: 0=ì›”ìš”ì¼, 5=í† ìš”ì¼)
    DRAW_DAYS = {
        "ìŠ¹ë¬´íŒ¨": [5],  # í† ìš”ì¼
        "ìŠ¹5íŒ¨": [2, 5]  # ìˆ˜ìš”ì¼, í† ìš”ì¼
    }

    @classmethod
    def get_next_draw_date(cls, game_type: str = "ìŠ¹ë¬´íŒ¨") -> datetime:
        """ë‹¤ìŒ ì¶”ì²¨ì¼ ì¡°íšŒ"""
        now = datetime.now(timezone.utc)
        draw_days = cls.DRAW_DAYS.get(game_type, [5])

        # ë‹¤ìŒ ì¶”ì²¨ì¼ ì°¾ê¸°
        for i in range(7):
            future_date = now + timedelta(days=i)
            if future_date.weekday() in draw_days:
                # ì¶”ì²¨ì¼ ì˜¤í›„ 8ì‹œë¡œ ì„¤ì •
                return future_date.replace(hour=20, minute=0, second=0, microsecond=0)

        return now  # fallback

    @classmethod
    def days_until_draw(cls, game_type: str = "ìŠ¹ë¬´íŒ¨") -> int:
        """ì¶”ì²¨ì¼ê¹Œì§€ ë‚¨ì€ ì¼ìˆ˜"""
        now = datetime.now(timezone.utc)
        next_draw = cls.get_next_draw_date(game_type)
        delta = next_draw - now
        return delta.days

    @classmethod
    def should_analyze_now(cls, game_type: str = "ìŠ¹ë¬´íŒ¨") -> bool:
        """í˜„ì¬ ë¶„ì„ì„ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨

        ì¶”ì²¨ì¼ 2ì¼ ì „ë¶€í„° ë¶„ì„ ì‹œì‘
        """
        days_left = cls.days_until_draw(game_type)
        return days_left <= 2


class CostOptimizer:
    """ë¹„ìš© ìµœì í™” ì „ëµ"""

    def __init__(self):
        self.analysis_cache: Dict[str, dict] = {}  # round_id -> result
        self.analysis_timestamps: Dict[str, datetime] = {}

    def get_recommended_mode(
        self,
        round_id: str,
        game_type: str = "ìŠ¹ë¬´íŒ¨",
        force_full: bool = False
    ) -> AnalysisMode:
        """ê¶Œì¥ ë¶„ì„ ëª¨ë“œ ê²°ì •

        Args:
            round_id: íšŒì°¨ ID
            game_type: ê²Œì„ íƒ€ì…
            force_full: ê°•ì œë¡œ ì „ì²´ ë¶„ì„ ìˆ˜í–‰

        Returns:
            ê¶Œì¥ë˜ëŠ” ë¶„ì„ ëª¨ë“œ
        """
        if force_full:
            return AnalysisMode.FULL

        # ìºì‹œ í™•ì¸
        if round_id in self.analysis_cache:
            cached_time = self.analysis_timestamps.get(round_id)
            if cached_time:
                age_hours = (datetime.now(timezone.utc) - cached_time).total_seconds() / 3600
                # 6ì‹œê°„ ì´ë‚´ ìºì‹œëŠ” ì¬ì‚¬ìš©
                if age_hours < 6:
                    logger.info(f"Using cached analysis for {round_id} (age: {age_hours:.1f}h)")
                    return AnalysisMode.CACHED

        # ì¶”ì²¨ì¼ê¹Œì§€ ë‚¨ì€ ì‹œê°„ì— ë”°ë¼ ê²°ì •
        days_left = ProtoSchedule.days_until_draw(game_type)

        if days_left > 2:
            logger.info(f"Draw is {days_left} days away - skipping analysis")
            return AnalysisMode.QUICK
        elif days_left == 2:
            logger.info(f"Draw is 2 days away - quick analysis mode")
            return AnalysisMode.QUICK
        else:  # 1ì¼ ì „ ë˜ëŠ” ë‹¹ì¼
            logger.info(f"Draw is {days_left} days away - full analysis mode")
            return AnalysisMode.FULL

    def cache_result(self, round_id: str, result: dict):
        """ë¶„ì„ ê²°ê³¼ ìºì‹±"""
        self.analysis_cache[round_id] = result
        self.analysis_timestamps[round_id] = datetime.now(timezone.utc)
        logger.info(f"Cached analysis for {round_id}")

    def get_cached_result(self, round_id: str) -> Optional[dict]:
        """ìºì‹œëœ ê²°ê³¼ ì¡°íšŒ"""
        return self.analysis_cache.get(round_id)

    def clear_old_cache(self, max_age_hours: int = 24):
        """ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬"""
        now = datetime.now(timezone.utc)
        to_remove = []

        for round_id, timestamp in self.analysis_timestamps.items():
            age_hours = (now - timestamp).total_seconds() / 3600
            if age_hours > max_age_hours:
                to_remove.append(round_id)

        for round_id in to_remove:
            del self.analysis_cache[round_id]
            del self.analysis_timestamps[round_id]
            logger.info(f"Removed old cache for {round_id}")

    def get_model_config(self, mode: AnalysisMode) -> Dict[str, any]:
        """ë¶„ì„ ëª¨ë“œì— ë”°ë¥¸ AI ëª¨ë¸ ì„¤ì •

        Gemini í¬ë ˆë”§ í™œìš© ì „ëµ:
        - FULL ëª¨ë“œ: Geminië¥¼ ë°ì´í„° ìˆ˜ì§‘/ë¶„ì„ ê¸°ë°˜ìœ¼ë¡œ í™œìš©
        - QUICK ëª¨ë“œ: Geminië¡œ ë¹ ë¥¸ ì‚¬ì „ ë¶„ì„
        - ë¹„ìš© ë¶€ë‹´ ì—†ì´ ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ê°€ëŠ¥

        Returns:
            model_config: {
                'primary': ì£¼ ë¶„ì„ ëª¨ë¸,
                'secondary': ë³´ì¡° ëª¨ë¸,
                'data_collector': ë°ì´í„° ìˆ˜ì§‘ ëª¨ë¸,
                'iterations': ë°˜ë³µ íšŸìˆ˜
            }
        """
        if mode == AnalysisMode.FULL:
            # ìµœìƒìœ„ ëª¨ë¸ë¡œ ì‹¬ì¸µ ë¶„ì„ + Geminië¡œ ë°ì´í„° ìˆ˜ì§‘
            return {
                'data_collector': 'gemini-pro',  # ğŸ’ ë°ì´í„° ìˆ˜ì§‘ ì „ë‹´ (í¬ë ˆë”§ í™œìš©)
                'primary': 'o3',  # OpenAI o3 (ìµœê³  ì„±ëŠ¥)
                'secondary': 'kimi-k2-thinking',  # Kimi K2 (ì¶”ë¡  íŠ¹í™”)
                'tertiary': 'claude-sonnet',  # Claude Sonnet (ê· í˜•)
                'iterations': 1,
                'consensus_weight': {
                    'gemini-pro': 0.15,  # ë°ì´í„° ê¸°ë°˜ ë¶„ì„
                    'o3': 0.35,
                    'kimi-k2-thinking': 0.35,
                    'claude-sonnet': 0.15
                },
                'use_gemini_for_data': True  # Geminië¡œ ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘
            }
        elif mode == AnalysisMode.QUICK:
            # ë¹ ë¥¸ ì‚¬ì „ ë¶„ì„ - Gemini ë‹¨ë… ì‚¬ìš©
            return {
                'data_collector': 'gemini-pro',  # ğŸ’ í¬ë ˆë”§ í™œìš©
                'primary': 'gemini-pro',  # ë¹ ë¥´ê³  ë¹„ìš© ë¬´ë£Œ
                'secondary': None,
                'tertiary': None,
                'iterations': 1,
                'consensus_weight': {
                    'gemini-pro': 1.0
                },
                'use_gemini_for_data': True  # ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ê°€ëŠ¥
            }
        else:  # CACHED
            return {
                'data_collector': None,
                'primary': None,
                'secondary': None,
                'tertiary': None,
                'iterations': 0,
                'consensus_weight': {},
                'use_gemini_for_data': False
            }

    def estimate_cost(self, mode: AnalysisMode, num_matches: int = 14) -> Dict[str, float]:
        """ì˜ˆìƒ ë¹„ìš© ê³„ì‚°

        Args:
            mode: ë¶„ì„ ëª¨ë“œ
            num_matches: ê²½ê¸° ìˆ˜

        Returns:
            ë¹„ìš© ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        # ëª¨ë¸ë³„ ëŒ€ëµì ì¸ ë¹„ìš© (1000 í† í°ë‹¹ USD)
        COSTS = {
            'o3': 0.06,  # ê³ ë¹„ìš©
            'kimi-k2-thinking': 0.03,  # ì¤‘ê°„
            'claude-sonnet': 0.015,  # ì¤‘ê°„
            'claude-haiku': 0.00025,  # ë§¤ìš° ì €ë ´
            'gemini-pro': 0.0,  # ğŸ’ í¬ë ˆë”§ìœ¼ë¡œ ë¬´ë£Œ (140ë§Œì›)
        }

        # ê²½ê¸°ë‹¹ í‰ê·  í† í° ì‚¬ìš©ëŸ‰ (ì…ë ¥ + ì¶œë ¥)
        AVG_TOKENS_PER_MATCH = 3000

        config = self.get_model_config(mode)
        total_cost = 0.0
        breakdown = {}

        if mode == AnalysisMode.CACHED:
            return {'total': 0.0, 'breakdown': {}, 'savings': '100%', 'gemini_note': 'Using cache'}

        # ëª¨ë“  ëª¨ë¸ ë¹„ìš© ê³„ì‚° (data_collector í¬í•¨)
        for model_key in ['data_collector', 'primary', 'secondary', 'tertiary']:
            model = config.get(model_key)
            if model and model in COSTS:
                cost_per_match = (AVG_TOKENS_PER_MATCH / 1000) * COSTS[model]
                total = cost_per_match * num_matches * config['iterations']
                if total > 0:  # ë¹„ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ breakdownì— ì¶”ê°€
                    breakdown[model] = round(total, 4)
                total_cost += total

        # ì „ì²´ ë¶„ì„ ëŒ€ë¹„ ì ˆê°ë¥  ê³„ì‚°
        if mode == AnalysisMode.FULL:
            # FULL ëª¨ë“œëŠ” ê¸°ì¤€ì´ë¯€ë¡œ ì ˆê°ë¥  0%
            savings_pct = 0
            gemini_note = f'ğŸ’ Gemini ì‚¬ìš© (140ë§Œì› í¬ë ˆë”§)'
        else:
            # FULL ëª¨ë“œ ë¹„ìš©ì„ ì§ì ‘ ê³„ì‚° (ì¬ê·€ ë°©ì§€)
            full_config = self.get_model_config(AnalysisMode.FULL)
            full_cost = 0.0
            for model_key in ['data_collector', 'primary', 'secondary', 'tertiary']:
                model = full_config.get(model_key)
                if model and model in COSTS:
                    cost_per_match = (AVG_TOKENS_PER_MATCH / 1000) * COSTS[model]
                    full_cost += cost_per_match * num_matches * full_config['iterations']

            savings_pct = ((full_cost - total_cost) / full_cost * 100) if full_cost > 0 else 0

            if mode == AnalysisMode.QUICK:
                gemini_note = 'ğŸ’ Gemini ë‹¨ë… ì‚¬ìš© (ë¬´ë£Œ)'
            else:
                gemini_note = None

        result = {
            'total': round(total_cost, 4),
            'breakdown': breakdown,
            'savings': f"{savings_pct:.1f}%"
        }

        if gemini_note:
            result['gemini_note'] = gemini_note

        return result


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
cost_optimizer = CostOptimizer()

"""
ìµœì¢… 14ê²½ê¸° ë§ˆí‚¹ ë¦¬ìŠ¤íŠ¸ ìƒì„±
- AI í•©ì˜ë„ í¬í•¨
- ì‹ ë¢°ë„ ê¸°ë°˜ ë§ˆí‚¹
"""

from typing import Dict, List, Optional
from datetime import datetime
from collections import Counter


class MarkingGenerator:
    """14ê²½ê¸° ìµœì¢… ë§ˆí‚¹ ìƒì„±ê¸°"""

    def generate(
        self,
        round_analysis: Dict
    ) -> Dict:
        """
        ìµœì¢… ë§ˆí‚¹ ë¦¬ìŠ¤íŠ¸ ìƒì„±

        Args:
            round_analysis: {
                'round_id': '123',
                'matches': [...],
                'upsets': [...],
                'markings': [...]
            }

        Returns:
            {
                'round_id': '123',
                'final_markings': [
                    {
                        'game_no': 1,
                        'match_name': 'ë§¨ì‹œí‹° vs ì²¼ì‹œ',
                        'marking': ['í™ˆìŠ¹'],
                        'ai_consensus': '5/5 (100%)',
                        'confidence': 92,
                        'is_upset': False
                    },
                    ...
                ],
                'summary': {...}
            }
        """
        matches = round_analysis.get('matches', [])
        markings = round_analysis.get('markings', [])
        upsets = round_analysis.get('upsets', [])

        final_markings = []

        for i, match in enumerate(matches, 1):
            # í•´ë‹¹ ê²½ê¸°ì˜ ë§ˆí‚¹ ì •ë³´ ì°¾ê¸°
            marking_data = None
            if i <= len(markings):
                marking_data = markings[i-1]

            if not marking_data:
                # ë§ˆí‚¹ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ìƒì„±
                marking_data = {
                    'marking_type': 'single',
                    'marked_outcomes': ['home'],
                    'expected_hit_rate': 0.5,
                    'reasoning': 'ê¸°ë³¸ ë§ˆí‚¹'
                }

            # AI í•©ì˜ë„ ê³„ì‚°
            consensus = self._calculate_consensus(match)

            # í•œê¸€ ë³€í™˜
            marked_kr = self._translate_outcomes(
                marking_data.get('marked_outcomes', ['home'])
            )

            # ì´ë³€ ì—¬ë¶€
            is_upset = any(
                u.get('match_id') == match.get('id')
                for u in upsets
            )

            # í™•ë¥  ì •ë³´
            ai_pred = match.get('ai_prediction', {})
            probabilities = {
                'í™ˆìŠ¹': f"{ai_pred.get('home', 0.33):.0%}",
                'ë¬´ìŠ¹ë¶€': f"{ai_pred.get('draw', 0.33):.0%}",
                'ì›ì •ìŠ¹': f"{ai_pred.get('away', 0.33):.0%}"
            }

            final_markings.append({
                'game_no': i,
                'match_name': f"{match.get('home_team', 'Home')} vs {match.get('away_team', 'Away')}",
                'marking': marked_kr,
                'marking_type': marking_data.get('marking_type', 'single'),
                'ai_consensus': consensus['display'],
                'confidence': int(match.get('confidence', 0.5) * 100),
                'probabilities': probabilities,
                'is_upset': is_upset,
                'reasoning': marking_data.get('reasoning', '')
            })

        # ìš”ì•½ í†µê³„
        summary = self._generate_summary(final_markings, round_analysis)

        return {
            'round_id': round_analysis.get('round_id', ''),
            'final_markings': final_markings,
            'summary': summary,
            'generated_at': datetime.now().isoformat()
        }

    def _calculate_consensus(self, match: Dict) -> Dict:
        """
        AI í•©ì˜ë„ ê³„ì‚°

        Args:
            match: ê²½ê¸° ì •ë³´ (individual_predictions í¬í•¨)

        Returns:
            {
                'count': 3,
                'total': 5,
                'display': '3/5 (60%)',
                'outcome': 'home_win'
            }
        """
        # individual_predictionsì—ì„œ ê°€ì¥ ë§ì´ ì„ íƒëœ ê²°ê³¼ ì°¾ê¸°
        predictions = match.get('individual_predictions', [])

        if not predictions:
            return {
                'count': 0,
                'total': 5,
                'display': '0/5 (0%)',
                'outcome': 'unknown'
            }

        # ê° AIì˜ ìµœê³  ì˜ˆì¸¡ ì¶”ì¶œ
        best_outcomes = []
        for pred in predictions:
            # ì˜ˆì¸¡ ê²°ê³¼ê°€ í™•ë¥  í˜•íƒœì¸ ê²½ìš°
            if isinstance(pred, dict):
                # home_win_prob, draw_prob, away_win_prob í˜•íƒœ
                prob_keys = ['home_win_prob', 'draw_prob', 'away_win_prob']
                if all(k in pred for k in prob_keys):
                    best = max(prob_keys, key=lambda k: pred.get(k, 0))
                    best_outcomes.append(best.replace('_prob', ''))
                # home, draw, away í˜•íƒœ
                elif all(k in pred for k in ['home', 'draw', 'away']):
                    best = max(['home', 'draw', 'away'], key=lambda k: pred.get(k, 0))
                    best_outcomes.append(f"{best}_win" if best != 'draw' else 'draw')
            # ì˜ˆì¸¡ ê²°ê³¼ê°€ ë¬¸ìì—´ì¸ ê²½ìš°
            elif isinstance(pred, str):
                best_outcomes.append(pred)

        if not best_outcomes:
            return {
                'count': 0,
                'total': len(predictions),
                'display': f'0/{len(predictions)} (0%)',
                'outcome': 'unknown'
            }

        # ìµœë¹ˆê°’ ì°¾ê¸°
        counts = Counter(best_outcomes)
        most_common = counts.most_common(1)[0]
        consensus_count = most_common[1]
        total = len(predictions)

        return {
            'count': consensus_count,
            'total': total,
            'display': f"{consensus_count}/{total} ({consensus_count/total:.0%})",
            'outcome': most_common[0]
        }

    def _translate_outcomes(self, outcomes: List[str]) -> List[str]:
        """
        ì˜ì–´ â†’ í•œê¸€ ë³€í™˜

        Args:
            outcomes: ['home', 'draw', 'away']

        Returns:
            ['í™ˆìŠ¹', 'ë¬´ìŠ¹ë¶€', 'ì›ì •ìŠ¹']
        """
        translation = {
            'home': 'í™ˆìŠ¹',
            'draw': 'ë¬´ìŠ¹ë¶€',
            'away': 'ì›ì •ìŠ¹',
            'home_win': 'í™ˆìŠ¹',
            'away_win': 'ì›ì •ìŠ¹'
        }
        return [translation.get(o, o) for o in outcomes]

    def _generate_summary(self, final_markings: List[Dict], round_analysis: Dict) -> Dict:
        """
        ì „ì²´ ìš”ì•½ í†µê³„ ìƒì„±

        Args:
            final_markings: ìµœì¢… ë§ˆí‚¹ ë¦¬ìŠ¤íŠ¸
            round_analysis: ì „ì²´ ë¶„ì„ ê²°ê³¼

        Returns:
            ìš”ì•½ í†µê³„
        """
        total_games = len(final_markings)

        # ë§ˆí‚¹ íƒ€ì…ë³„ ê°œìˆ˜
        single_count = sum(1 for m in final_markings if m['marking_type'] == 'single')
        double_count = sum(1 for m in final_markings if m['marking_type'] == 'double')
        triple_count = sum(1 for m in final_markings if m['marking_type'] == 'triple')

        # ì´ë³€ í›„ë³´ ê°œìˆ˜
        upset_count = sum(1 for m in final_markings if m['is_upset'])

        # í‰ê·  ì‹ ë¢°ë„
        avg_confidence = sum(m['confidence'] for m in final_markings) / total_games if total_games > 0 else 0

        # ê³ ì‹ ë¢°ë„ ë‹¨ì‹ ê°œìˆ˜ (ì‹ ë¢°ë„ 80% ì´ìƒ)
        high_confidence_singles = sum(
            1 for m in final_markings
            if m['marking_type'] == 'single' and m['confidence'] >= 80
        )

        # ë³µìˆ˜ ë§ˆí‚¹ ë¹„ìœ¨
        multi_marking_ratio = (double_count + triple_count) / total_games if total_games > 0 else 0

        return {
            'total_games': total_games,
            'single_count': single_count,
            'double_count': double_count,
            'triple_count': triple_count,
            'upset_count': upset_count,
            'avg_confidence': round(avg_confidence, 1),
            'high_confidence_singles': high_confidence_singles,
            'multi_marking_ratio': round(multi_marking_ratio * 100, 1),
            'confidence_breakdown': {
                'high': sum(1 for m in final_markings if m['confidence'] >= 80),
                'medium': sum(1 for m in final_markings if 60 <= m['confidence'] < 80),
                'low': sum(1 for m in final_markings if m['confidence'] < 60)
            }
        }

    def format_for_display(self, result: Dict) -> str:
        """
        ì‚¬ìš©ì ì¹œí™”ì ì¸ í¬ë§·ìœ¼ë¡œ ë³€í™˜

        Args:
            result: generate() ê²°ê³¼

        Returns:
            í¬ë§·íŒ…ëœ ë¬¸ìì—´
        """
        lines = []
        lines.append("=" * 60)
        lines.append(f"ğŸ¯ í”„ë¡œí†  {result['round_id']}íšŒì°¨ ìµœì¢… ë§ˆí‚¹")
        lines.append("=" * 60)
        lines.append("")

        for marking in result['final_markings']:
            lines.append(f"ê²½ê¸° {marking['game_no']}: {marking['match_name']}")
            lines.append(f"  ë§ˆí‚¹: {', '.join(marking['marking'])} ({marking['marking_type']})")
            lines.append(f"  AI í•©ì˜: {marking['ai_consensus']} | ì‹ ë¢°ë„: {marking['confidence']}%")
            lines.append(f"  í™•ë¥ : {marking['probabilities']['í™ˆìŠ¹']} / {marking['probabilities']['ë¬´ìŠ¹ë¶€']} / {marking['probabilities']['ì›ì •ìŠ¹']}")

            if marking['is_upset']:
                lines.append("  âš ï¸ ì´ë³€ í›„ë³´")

            lines.append("")

        # ìš”ì•½
        summary = result['summary']
        lines.append("-" * 60)
        lines.append("ğŸ“Š ì „ì²´ ìš”ì•½")
        lines.append("-" * 60)
        lines.append(f"ì´ ê²½ê¸° ìˆ˜: {summary['total_games']}")
        lines.append(f"ë‹¨ì‹: {summary['single_count']}ê°œ (ê³ ì‹ ë¢°: {summary['high_confidence_singles']}ê°œ)")
        lines.append(f"2ê°œ ë³µìˆ˜: {summary['double_count']}ê°œ")
        lines.append(f"3ê°œ ë³µìˆ˜: {summary['triple_count']}ê°œ")
        lines.append(f"ì´ë³€ í›„ë³´: {summary['upset_count']}ê°œ")
        lines.append(f"í‰ê·  ì‹ ë¢°ë„: {summary['avg_confidence']}%")
        lines.append("")
        lines.append(f"ìƒì„± ì‹œê°: {result['generated_at']}")
        lines.append("=" * 60)

        return "\n".join(lines)

    def export_to_json(self, result: Dict, filepath: str):
        """
        JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°

        Args:
            result: generate() ê²°ê³¼
            filepath: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        """
        import json

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

    def export_to_csv(self, result: Dict, filepath: str):
        """
        CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°

        Args:
            result: generate() ê²°ê³¼
            filepath: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        """
        import csv

        with open(filepath, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(
                f,
                fieldnames=['game_no', 'match_name', 'marking', 'marking_type',
                           'ai_consensus', 'confidence', 'is_upset', 'reasoning']
            )
            writer.writeheader()

            for marking in result['final_markings']:
                row = marking.copy()
                row['marking'] = ', '.join(row['marking'])
                # probabilities í•„ë“œ ì œê±° (CSVì—ì„œëŠ” ë³µì¡ë„ ë‚®ì¶”ê¸°)
                row.pop('probabilities', None)
                writer.writerow(row)

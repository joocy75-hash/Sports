#!/usr/bin/env python3
"""
í”„ë¡œí†  14ê²½ê¸° AI ë¶„ì„ ì‹œìŠ¤í…œ - í†µí•© í…ŒìŠ¤íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ Mock ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ì‹¤ì œ API í˜¸ì¶œì„ ìµœì†Œí™”í•˜ê³  ì‹œìŠ¤í…œ í†µí•©ê³¼ ë°ì´í„° íë¦„ ê²€ì¦ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
"""

import asyncio
import json
import logging
from datetime import datetime
from typing import Dict, List

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_mock_match_data(match_id: int) -> Dict:
    """Mock ê²½ê¸° ë°ì´í„° ìƒì„±"""

    teams = [
        ("ë§¨ì²´ìŠ¤í„° ì‹œí‹°", "ì²¼ì‹œ", 1.65, 3.80, 5.20, 0.55, 0.25, 0.20),
        ("ë¦¬ë²„í’€", "ì•„ìŠ¤ë‚ ", 2.10, 3.40, 3.60, 0.42, 0.28, 0.30),
        ("ë°”ë¥´ì…€ë¡œë‚˜", "ë ˆì•Œ ë§ˆë“œë¦¬ë“œ", 2.35, 3.20, 3.10, 0.38, 0.30, 0.32),
        ("ë°”ì´ì—ë¥¸ ë®Œí—¨", "ë„ë¥´íŠ¸ë¬¸íŠ¸", 1.75, 3.60, 4.80, 0.52, 0.26, 0.22),
        ("íŒŒë¦¬ ìƒì œë¥´ë§¹", "ë§ˆë¥´ì„¸ìœ ", 1.55, 4.00, 6.00, 0.60, 0.23, 0.17),
        ("ìœ ë²¤íˆ¬ìŠ¤", "ì¸í„° ë°€ë€", 2.50, 3.10, 3.00, 0.36, 0.31, 0.33),
        ("ìš¸ë²„í–„íŠ¼", "ë§¨ì²´ìŠ¤í„° ìœ ë‚˜ì´í‹°ë“œ", 4.20, 3.50, 1.90, 0.22, 0.27, 0.51),
        ("ë ˆìŠ¤í„° ì‹œí‹°", "í† íŠ¸ë„˜", 3.80, 3.40, 2.05, 0.24, 0.28, 0.48),
        ("AC ë°€ë€", "ë‚˜í´ë¦¬", 2.80, 3.20, 2.65, 0.33, 0.30, 0.37),
        ("ì•„í‹€ë ˆí‹°ì½”", "ì„¸ë¹„ì•¼", 1.95, 3.30, 4.00, 0.46, 0.29, 0.25),
        ("ì²¼ì‹œ", "ë ˆìŠ¤í„°", 1.70, 3.70, 5.00, 0.54, 0.25, 0.21),
        ("ë¦¬ì˜¹", "ëª¨ë‚˜ì½”", 2.40, 3.15, 3.20, 0.37, 0.30, 0.33),
        ("ë°œë Œì‹œì•„", "ë¹Œë°”ì˜¤", 2.60, 3.10, 2.90, 0.35, 0.31, 0.34),
        ("ë² ë¥´ë” ë¸Œë ˆë©˜", "í”„ë‘í¬í‘¸ë¥´íŠ¸", 3.50, 3.30, 2.20, 0.26, 0.29, 0.45),
    ]

    if match_id > len(teams):
        match_id = 1

    home, away, h_odd, d_odd, a_odd, h_prob, d_prob, a_prob = teams[match_id - 1]

    return {
        "match_id": f"match_{match_id}",
        "home_team": {"name": home},
        "away_team": {"name": away},
        "league": "í”„ë¦¬ë¯¸ì–´ ë¦¬ê·¸" if match_id <= 8 else "ë¼ë¦¬ê°€",
        "match_time": f"2025-12-24 {19 + (match_id % 5)}:00:00",
        "official_odds": {
            "home_win": h_odd,
            "draw": d_odd,
            "away_win": a_odd
        },
        # Mock íŒ€ í†µê³„
        "home_stats": {
            "league_rank": 3,
            "recent_form": "WWDWW",  # ìµœê·¼ 5ê²½ê¸°
            "avg_goals_scored": 2.1,
            "avg_goals_conceded": 0.9,
            "home_record": {"wins": 8, "draws": 3, "losses": 1},
        },
        "away_stats": {
            "league_rank": 5,
            "recent_form": "WDLWW",
            "avg_goals_scored": 1.8,
            "avg_goals_conceded": 1.2,
            "away_record": {"wins": 6, "draws": 4, "losses": 2},
        },
        # Mock H2H
        "h2h": {
            "total_matches": 10,
            "home_wins": 4,
            "draws": 3,
            "away_wins": 3,
            "home_goals": 15,
            "away_goals": 12,
        },
        # AI ì˜ˆì¸¡ (Mock)
        "ai_prediction": {
            "home_win_prob": h_prob,
            "draw_prob": d_prob,
            "away_win_prob": a_prob,
        },
        "confidence": 0.75 + (match_id % 3) * 0.08,
    }


def create_mock_round_data(num_matches: int = 14) -> List[Dict]:
    """Mock íšŒì°¨ ë°ì´í„° ìƒì„± (14ê²½ê¸°)"""
    return [create_mock_match_data(i) for i in range(1, num_matches + 1)]


async def test_individual_modules():
    """ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""

    logger.info("=" * 80)
    logger.info("ğŸ§ª ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 80)

    results = {
        "upset_detector": False,
        "multi_marking_optimizer": False,
        "marking_generator": False,
        "telegram_notifier": False,
    }

    # 1. ì´ë³€ ê°ì§€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    logger.info("\nğŸ“Œ 1. ì´ë³€ ê°ì§€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    try:
        from src.services.upset_detector import UpsetDetector

        detector = UpsetDetector()
        test_match = create_mock_match_data(7)  # ìš¸ë²„í–„íŠ¼ vs ë§¨ìœ 

        upset_result = detector.detect_upsets(
            ai_prediction=test_match["ai_prediction"],
            official_odds=test_match["official_odds"],
            confidence=test_match["confidence"]
        )

        logger.info(f"   âœ… ì´ë³€ ê°ì§€ ì„±ê³µ")
        logger.info(f"      - ì´ë³€ í›„ë³´: {upset_result['is_upset_candidate']}")
        logger.info(f"      - ê´´ë¦¬ë„: {upset_result['divergence']:.2%}")
        logger.info(f"      - ë¦¬ìŠ¤í¬: {upset_result['risk_level']}")

        results["upset_detector"] = True

    except Exception as e:
        logger.error(f"   âŒ ì´ë³€ ê°ì§€ ì‹¤íŒ¨: {e}")

    # 2. ë³µìˆ˜ ë§ˆí‚¹ ìµœì í™” í…ŒìŠ¤íŠ¸
    logger.info("\nğŸ“Œ 2. ë³µìˆ˜ ë§ˆí‚¹ ìµœì í™” í…ŒìŠ¤íŠ¸")
    try:
        from src.services.multi_marking_optimizer import MultiMarkingOptimizer

        optimizer = MultiMarkingOptimizer()
        test_match = create_mock_match_data(2)  # ë¦¬ë²„í’€ vs ì•„ìŠ¤ë‚ 

        marking_result = optimizer.optimize_marking({
            'id': test_match['match_id'],
            'home_team': test_match['home_team']['name'],
            'away_team': test_match['away_team']['name'],
            'ai_prediction': test_match['ai_prediction'],
            'confidence': test_match['confidence'],
            'official_odds': test_match['official_odds'],
            'individual_predictions': []
        })

        logger.info(f"   âœ… ë³µìˆ˜ ë§ˆí‚¹ ìµœì í™” ì„±ê³µ")
        logger.info(f"      - ë§ˆí‚¹ íƒ€ì…: {marking_result['marking_type']}")
        logger.info(f"      - ë§ˆí‚¹ ê²°ê³¼: {marking_result['marked_outcomes']}")
        logger.info(f"      - ì˜ˆìƒ ì ì¤‘ë¥ : {marking_result['expected_hit_rate']:.2%}")

        results["multi_marking_optimizer"] = True

    except Exception as e:
        logger.error(f"   âŒ ë³µìˆ˜ ë§ˆí‚¹ ìµœì í™” ì‹¤íŒ¨: {e}")

    # 3. ìµœì¢… ë§ˆí‚¹ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸
    logger.info("\nğŸ“Œ 3. ìµœì¢… ë§ˆí‚¹ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸")
    try:
        from src.services.marking_generator import MarkingGenerator

        generator = MarkingGenerator()
        mock_matches = create_mock_round_data(3)  # 3ê²½ê¸°ë§Œ í…ŒìŠ¤íŠ¸

        # Mock ë§ˆí‚¹ ê²°ê³¼
        mock_markings = [
            {
                'match_id': m['match_id'],
                'home_team': m['home_team']['name'],
                'away_team': m['away_team']['name'],
                'marking_type': 'single',
                'marked_outcomes': ['home'],
                'expected_hit_rate': 0.55,
                'expected_value': 0.91,
                'reasoning': 'ê³ ì‹ ë¢°ë„ ë‹¨ì‹'
            }
            for m in mock_matches
        ]

        final_result = generator.generate({
            'round_id': 'TEST_123',
            'matches': [
                {
                    'id': m['match_id'],
                    'home_team': m['home_team']['name'],
                    'away_team': m['away_team']['name'],
                    'ai_prediction': m['ai_prediction'],
                    'confidence': m['confidence'],
                    'individual_predictions': [],
                    'official_odds': m['official_odds']
                }
                for m in mock_matches
            ],
            'upsets': [],
            'markings': mock_markings
        })

        logger.info(f"   âœ… ìµœì¢… ë§ˆí‚¹ ìƒì„± ì„±ê³µ")
        logger.info(f"      - íšŒì°¨: {final_result['round_id']}")
        logger.info(f"      - ê²½ê¸° ìˆ˜: {len(final_result['final_markings'])}")
        logger.info(f"      - í‰ê·  ì‹ ë¢°ë„: {final_result['summary']['avg_confidence']:.0f}%")

        results["marking_generator"] = True

    except Exception as e:
        logger.error(f"   âŒ ìµœì¢… ë§ˆí‚¹ ìƒì„± ì‹¤íŒ¨: {e}")

    # 4. í…”ë ˆê·¸ë¨ ì•Œë¦¼ í…ŒìŠ¤íŠ¸ (ëª¨ë“ˆë§Œ í™•ì¸)
    logger.info("\nğŸ“Œ 4. í…”ë ˆê·¸ë¨ ì•Œë¦¼ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    try:
        from src.services.telegram_notifier import TelegramNotifier

        notifier = TelegramNotifier()
        logger.info(f"   âœ… í…”ë ˆê·¸ë¨ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
        logger.info(f"      - Bot Token ì„¤ì •: {'âœ…' if notifier.bot_token else 'âŒ'}")
        logger.info(f"      - Chat ID ì„¤ì •: {'âœ…' if notifier.chat_id else 'âŒ'}")

        results["telegram_notifier"] = True

    except Exception as e:
        logger.error(f"   âŒ í…”ë ˆê·¸ë¨ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")

    return results


async def test_integrated_pipeline():
    """í†µí•© íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ”— í†µí•© íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 80)

    try:
        from src.main_pipeline import OddsPipeline
        from src.preprocessing.feature_engineer import SportType

        # Mock ë°ì´í„° ìƒì„±
        mock_matches = create_mock_round_data(14)

        # ê³µì‹ ë°°ë‹¹ ì¶”ì¶œ
        official_odds = {
            m['match_id']: m['official_odds']
            for m in mock_matches
        }

        logger.info(f"\nğŸ“Š Mock ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
        logger.info(f"   - ê²½ê¸° ìˆ˜: {len(mock_matches)}")
        logger.info(f"   - ê³µì‹ ë°°ë‹¹: {len(official_odds)}ê°œ")

        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        logger.info(f"\nğŸ”§ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
        pipeline = OddsPipeline(
            sport_type=SportType.SOCCER,
            margin=0.05,
            use_perplexity=False  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ë¹„í™œì„±í™”
        )

        # ëª¨ë¸ ìƒíƒœ í™•ì¸
        model_status = pipeline.get_model_status()
        logger.info(f"\nğŸ¤– AI ëª¨ë¸ ìƒíƒœ:")
        logger.info(f"   - LLM AI: {'âœ…' if model_status['llm_ai']['available'] else 'âŒ'}")
        logger.info(f"   - ML ëª¨ë¸: {'âœ…' if model_status['ml']['available'] else 'âŒ'}")
        logger.info(f"   - í†µê³„ ëª¨ë¸: {'âœ…' if model_status['statistical']['available'] else 'âŒ'}")

        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        logger.info(f"\nğŸš€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
        logger.info(f"   (ì‹¤ì œ AI ë¶„ì„ ëŒ€ì‹  Mock ë°ì´í„° ì‚¬ìš©)")

        result = await pipeline.analyze_round(
            round_id="TEST_123",
            matches_data=mock_matches,
            official_odds=official_odds
        )

        # ê²°ê³¼ ê²€ì¦
        logger.info(f"\nâœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
        logger.info(f"\nğŸ“‹ ê²°ê³¼ ìš”ì•½:")
        logger.info(f"   - íšŒì°¨ ID: {result.round_id}")
        logger.info(f"   - ë¶„ì„ ê²½ê¸° ìˆ˜: {len(result.matches)}")
        logger.info(f"   - ê³ ì‹ ë¢°ë„ ê²½ê¸°: {result.summary.get('high_confidence_matches', 0)}")
        logger.info(f"   - Value Bet ë°œê²¬: {result.summary.get('value_bets_found', 0)}")
        logger.info(f"   - í‰ê·  AI í•©ì˜ë„: {result.summary.get('avg_consensus', 0):.1%}")
        logger.info(f"   - ì´ë³€ í›„ë³´: {result.summary.get('upset_count', 0)}ê²½ê¸°")
        logger.info(f"   - ë³µìˆ˜ ë§ˆí‚¹: {result.summary.get('multi_marking_count', 0)}ê²½ê¸°")

        # ìµœì¢… ë§ˆí‚¹ í™•ì¸
        final_markings = result.summary.get('final_markings', {})
        if final_markings:
            logger.info(f"\nğŸ“ ìµœì¢… ë§ˆí‚¹ í†µê³„:")
            summary = final_markings.get('summary', {})
            logger.info(f"   - ë‹¨ì‹: {summary.get('single_count', 0)}ê²½ê¸°")
            logger.info(f"   - 2ê°œ ë³µìˆ˜: {summary.get('double_count', 0)}ê²½ê¸°")
            logger.info(f"   - 3ê°œ ë³µìˆ˜: {summary.get('triple_count', 0)}ê²½ê¸°")

        # ì¶”ì²œ ì¡°í•©
        if result.combinations:
            logger.info(f"\nğŸ† ì¶”ì²œ ì¡°í•© (ìƒìœ„ 3ê°œ):")
            for i, combo in enumerate(result.combinations[:3], 1):
                logger.info(f"   {i}. {combo.get('name', 'Unknown')}")
                logger.info(f"      - ì˜ˆìƒ ROI: {combo.get('metrics', {}).get('expected_roi', 0):.1%}")

        return True, result

    except Exception as e:
        logger.error(f"\nâŒ í†µí•© íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False, None


async def generate_test_report(
    individual_results: Dict[str, bool],
    pipeline_success: bool,
    pipeline_result
):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸")
    logger.info("=" * 80)

    # ê°œë³„ ëª¨ë“ˆ ê²°ê³¼
    logger.info("\nâœ… ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    for module, success in individual_results.items():
        status = "âœ… PASS" if success else "âŒ FAIL"
        logger.info(f"   - {module}: {status}")

    # í†µí•© íŒŒì´í”„ë¼ì¸ ê²°ê³¼
    logger.info(f"\nâœ… í†µí•© íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸:")
    logger.info(f"   - ìƒíƒœ: {'âœ… PASS' if pipeline_success else 'âŒ FAIL'}")

    # ì „ì²´ í†µê³¼ìœ¨
    individual_pass = sum(individual_results.values())
    individual_total = len(individual_results)
    overall_pass_rate = (individual_pass + (1 if pipeline_success else 0)) / (individual_total + 1)

    logger.info(f"\nğŸ“ˆ ì „ì²´ í†µê³¼ìœ¨:")
    logger.info(f"   - ê°œë³„ ëª¨ë“ˆ: {individual_pass}/{individual_total} ({individual_pass/individual_total:.0%})")
    logger.info(f"   - ì „ì²´: {overall_pass_rate:.0%}")

    # JSON ë¦¬í¬íŠ¸ ìƒì„±
    report = {
        "test_date": datetime.now().isoformat(),
        "test_type": "integration_test",
        "individual_modules": individual_results,
        "integrated_pipeline": {
            "success": pipeline_success,
            "result_summary": None
        },
        "overall_pass_rate": overall_pass_rate,
    }

    if pipeline_success and pipeline_result:
        report["integrated_pipeline"]["result_summary"] = {
            "round_id": pipeline_result.round_id,
            "total_matches": len(pipeline_result.matches),
            "summary": pipeline_result.summary,
        }

    # íŒŒì¼ ì €ì¥
    report_path = f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=str)

    logger.info(f"\nğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")

    return report


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

    logger.info("ğŸš€ í”„ë¡œí†  14ê²½ê¸° AI ë¶„ì„ ì‹œìŠ¤í…œ - í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # 1. ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    individual_results = await test_individual_modules()

    # 2. í†µí•© íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    pipeline_success, pipeline_result = await test_integrated_pipeline()

    # 3. í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
    await generate_test_report(individual_results, pipeline_success, pipeline_result)

    logger.info("\n" + "=" * 80)
    logger.info("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    logger.info(f"â° ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
